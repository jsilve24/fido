<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Function to Optimize the Collapsed Pibble Model — optimPibbleCollapsed • fido</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Function to Optimize the Collapsed Pibble Model — optimPibbleCollapsed"><meta name="description" content="See details for model. Should likely be followed by function
uncollapsePibble. Notation: N is number of samples,
D is number of multinomial categories, and Q is number
of covariates."><meta property="og:description" content="See details for model. Should likely be followed by function
uncollapsePibble. Notation: N is number of samples,
D is number of multinomial categories, and Q is number
of covariates."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">fido</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">1.1.2</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/introduction-to-fido.html">Introduction to fido::Pibble</a></li>
    <li><a class="dropdown-item" href="../articles/non-linear-models.html">Non-linear models with fido::basset</a></li>
    <li><a class="dropdown-item" href="../articles/orthus.html">Joint Modeling  (e.g., Multiomics) with fido::Orthus</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><a class="dropdown-item" href="../articles/index.html">More articles...</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/jsilve24/fido/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Function to Optimize the Collapsed Pibble Model</h1>
      <small class="dont-index">Source: <a href="https://github.com/jsilve24/fido/blob/master/R/RcppExports.R" class="external-link"><code>R/RcppExports.R</code></a></small>
      <div class="d-none name"><code>optimPibbleCollapsed.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>See details for model. Should likely be followed by function
<code><a href="uncollapsePibble.html">uncollapsePibble</a></code>. Notation: <code>N</code> is number of samples,
<code>D</code> is number of multinomial categories, and <code>Q</code> is number
of covariates.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">optimPibbleCollapsed</span><span class="op">(</span></span>
<span>  <span class="va">Y</span>,</span>
<span>  <span class="va">upsilon</span>,</span>
<span>  <span class="va">ThetaX</span>,</span>
<span>  <span class="va">KInv</span>,</span>
<span>  <span class="va">AInv</span>,</span>
<span>  <span class="va">init</span>,</span>
<span>  n_samples <span class="op">=</span> <span class="fl">2000L</span>,</span>
<span>  calcGradHess <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  b1 <span class="op">=</span> <span class="fl">0.9</span>,</span>
<span>  b2 <span class="op">=</span> <span class="fl">0.99</span>,</span>
<span>  step_size <span class="op">=</span> <span class="fl">0.003</span>,</span>
<span>  epsilon <span class="op">=</span> <span class="fl">1e-06</span>,</span>
<span>  eps_f <span class="op">=</span> <span class="fl">1e-10</span>,</span>
<span>  eps_g <span class="op">=</span> <span class="fl">1e-04</span>,</span>
<span>  max_iter <span class="op">=</span> <span class="fl">10000L</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  verbose_rate <span class="op">=</span> <span class="fl">10L</span>,</span>
<span>  decomp_method <span class="op">=</span> <span class="st">"cholesky"</span>,</span>
<span>  optim_method <span class="op">=</span> <span class="st">"lbfgs"</span>,</span>
<span>  eigvalthresh <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  jitter <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  multDirichletBoot <span class="op">=</span> <span class="op">-</span><span class="fl">1</span>,</span>
<span>  useSylv <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  ncores <span class="op">=</span> <span class="op">-</span><span class="fl">1L</span>,</span>
<span>  seed <span class="op">=</span> <span class="op">-</span><span class="fl">1L</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-y">Y<a class="anchor" aria-label="anchor" href="#arg-y"></a></dt>
<dd><p>D x N matrix of counts</p></dd>


<dt id="arg-upsilon">upsilon<a class="anchor" aria-label="anchor" href="#arg-upsilon"></a></dt>
<dd><p>(must be &gt; D)</p></dd>


<dt id="arg-thetax">ThetaX<a class="anchor" aria-label="anchor" href="#arg-thetax"></a></dt>
<dd><p>D-1 x N matrix formed by Theta*X (Theta is Prior mean
for regression coefficients)</p></dd>


<dt id="arg-kinv">KInv<a class="anchor" aria-label="anchor" href="#arg-kinv"></a></dt>
<dd><p>D-1 x D-1 precision matrix (inverse of Xi)</p></dd>


<dt id="arg-ainv">AInv<a class="anchor" aria-label="anchor" href="#arg-ainv"></a></dt>
<dd><p>N x N precision matrix given by \((I_N + X'*Gamma*X)^{-1}\)</p></dd>


<dt id="arg-init">init<a class="anchor" aria-label="anchor" href="#arg-init"></a></dt>
<dd><p>D-1 x N matrix of initial guess for eta used for optimization</p></dd>


<dt id="arg-n-samples">n_samples<a class="anchor" aria-label="anchor" href="#arg-n-samples"></a></dt>
<dd><p>number of samples for Laplace Approximation (=0 very fast
as no inversion or decomposition of Hessian is required)</p></dd>


<dt id="arg-calcgradhess">calcGradHess<a class="anchor" aria-label="anchor" href="#arg-calcgradhess"></a></dt>
<dd><p>if n_samples=0 should Gradient and Hessian
still be calculated using closed form solutions?</p></dd>


<dt id="arg-b-">b1<a class="anchor" aria-label="anchor" href="#arg-b-"></a></dt>
<dd><p>(ADAM) 1st moment decay parameter (recommend 0.9) "aka momentum"</p></dd>


<dt id="arg-b-">b2<a class="anchor" aria-label="anchor" href="#arg-b-"></a></dt>
<dd><p>(ADAM) 2nd moment decay parameter (recommend 0.99 or 0.999)</p></dd>


<dt id="arg-step-size">step_size<a class="anchor" aria-label="anchor" href="#arg-step-size"></a></dt>
<dd><p>(ADAM) step size for descent (recommend 0.001-0.003)</p></dd>


<dt id="arg-epsilon">epsilon<a class="anchor" aria-label="anchor" href="#arg-epsilon"></a></dt>
<dd><p>(ADAM) parameter to avoid divide by zero</p></dd>


<dt id="arg-eps-f">eps_f<a class="anchor" aria-label="anchor" href="#arg-eps-f"></a></dt>
<dd><p>(ADAM) normalized function improvement stopping criteria</p></dd>


<dt id="arg-eps-g">eps_g<a class="anchor" aria-label="anchor" href="#arg-eps-g"></a></dt>
<dd><p>(ADAM) normalized gradient magnitude stopping criteria</p></dd>


<dt id="arg-max-iter">max_iter<a class="anchor" aria-label="anchor" href="#arg-max-iter"></a></dt>
<dd><p>(ADAM) maximum number of iterations before stopping</p></dd>


<dt id="arg-verbose">verbose<a class="anchor" aria-label="anchor" href="#arg-verbose"></a></dt>
<dd><p>(ADAM) if true will print stats for stopping criteria and
iteration number</p></dd>


<dt id="arg-verbose-rate">verbose_rate<a class="anchor" aria-label="anchor" href="#arg-verbose-rate"></a></dt>
<dd><p>(ADAM) rate to print verbose stats to screen</p></dd>


<dt id="arg-decomp-method">decomp_method<a class="anchor" aria-label="anchor" href="#arg-decomp-method"></a></dt>
<dd><p>decomposition of hessian for Laplace approximation
'eigen' (more stable-slightly, slower) or 'cholesky' (less stable, faster, default)</p></dd>


<dt id="arg-optim-method">optim_method<a class="anchor" aria-label="anchor" href="#arg-optim-method"></a></dt>
<dd><p>(default:"lbfgs") or "adam"</p></dd>


<dt id="arg-eigvalthresh">eigvalthresh<a class="anchor" aria-label="anchor" href="#arg-eigvalthresh"></a></dt>
<dd><p>threshold for negative eigenvalues in
decomposition of negative inverse hessian (should be &lt;=0)</p></dd>


<dt id="arg-jitter">jitter<a class="anchor" aria-label="anchor" href="#arg-jitter"></a></dt>
<dd><p>(default: 0) if &gt;=0 then adds that factor to diagonal of Hessian
before decomposition (to improve matrix conditioning)</p></dd>


<dt id="arg-multdirichletboot">multDirichletBoot<a class="anchor" aria-label="anchor" href="#arg-multdirichletboot"></a></dt>
<dd><p>if &gt;0 then it overrides laplace approximation and samples
eta efficiently at MAP estimate from pseudo Multinomial-Dirichlet posterior.</p></dd>


<dt id="arg-usesylv">useSylv<a class="anchor" aria-label="anchor" href="#arg-usesylv"></a></dt>
<dd><p>(default: true) if N&lt;D-1 uses Sylvester Determinant Identity
to speed up calculation of log-likelihood and gradients.</p></dd>


<dt id="arg-ncores">ncores<a class="anchor" aria-label="anchor" href="#arg-ncores"></a></dt>
<dd><p>(default:-1) number of cores to use, if ncores==-1 then
uses default from OpenMP typically to use all available cores.</p></dd>


<dt id="arg-seed">seed<a class="anchor" aria-label="anchor" href="#arg-seed"></a></dt>
<dd><p>(random seed for Laplace approximation – integer)</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>List containing (all with respect to found optima)</p><ol><li><p>LogLik - Log Likelihood of collapsed model (up to proportionality constant)</p></li>
<li><p>Gradient - (if <code>calcGradHess</code>=true)</p></li>
<li><p>Hessian - (if <code>calcGradHess</code>=true) of the POSITIVE LOG POSTERIOR</p></li>
<li><p>Pars - Parameter value of eta at optima</p></li>
<li><p>Samples - (D-1) x N x n_samples array containing posterior samples of eta
based on Laplace approximation (if n_samples&gt;0)</p></li>
<li><p>Timer - Vector of Execution Times</p></li>
<li><p>logInvNegHessDet - the log determinant of the covariacne of the Laplace
approximation, useful for calculating marginal likelihood</p></li>
<li><p>logMarginalLikelihood - A calculation of the log marginal likelihood based on
the laplace approximation</p></li>
</ol></div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>Notation: Let \(Z_j\) denote the J-th row of a matrix Z.
Model:
$$Y_j \sim Multinomial(\pi_j)$$
$$\pi_j = \Phi^{-1}(\eta_j)$$
$$\eta \sim T_{D-1, N}(\upsilon, \Theta X, K, A)$$
Where \(A = I_N + X  \Gamma X'\), K is a (D-1)x(D-1) covariance
matrix, \(\Gamma\) is a Q x Q covariance matrix, and \(\Phi^{-1}\) is ALRInv_D
transform.</p>
<p>Gradient and Hessian calculations are fast as they are computed using closed
form solutions. That said, the Hessian matrix can be quite large
[N*(D-1) x N*(D-1)] and storage may be an issue.</p>
<p>Note: Warnings about large negative eigenvalues can either signal
that the optimizer did not reach an optima or (more commonly in my experience)
that the prior / degrees of freedom for the covariance (given by parameters
<code>upsilon</code> and <code>KInv</code>) were too specific and at odds with the observed data.
If you get this warning try the following.</p><ol><li><p>Try restarting the optimization using a different initial guess for eta</p></li>
<li><p>Try decreasing (or even increasing )<code>step_size</code> (by increments of 0.001 or 0.002)
and increasing <code>max_iter</code> parameters in optimizer. Also can try
increasing <code>b1</code> to 0.99 and decreasing <code>eps_f</code> by a few orders
of magnitude</p></li>
<li><p>Try relaxing prior assumptions regarding covariance matrix. (e.g., may want
to consider decreasing parameter <code>upsilon</code> closer to a minimum value of
D)</p></li>
<li><p>Try adding small amount of jitter (e.g., set <code>jitter=1e-5</code>) to address
potential floating point errors.</p></li>
</ol></div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>S. Ruder (2016) <em>An overview of gradient descent
optimization algorithms</em>. arXiv 1609.04747</p>
<p>JD Silverman K Roche, ZC Holmes, LA David, S Mukherjee.
<em>Bayesian Multinomial Logistic Normal Models through Marginally Latent Matrix-T Processes</em>.
2022, Journal of Machine Learning</p>
    </div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p><code><a href="uncollapsePibble.html">uncollapsePibble</a></code></p></div>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="va">sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="pibble_sim.html">pibble_sim</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Fit model for eta</span></span></span>
<span class="r-in"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu">optimPibbleCollapsed</span><span class="op">(</span><span class="va">sim</span><span class="op">$</span><span class="va">Y</span>, <span class="va">sim</span><span class="op">$</span><span class="va">upsilon</span>, <span class="va">sim</span><span class="op">$</span><span class="va">Theta</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span><span class="va">sim</span><span class="op">$</span><span class="va">X</span>, <span class="va">sim</span><span class="op">$</span><span class="va">KInv</span>, </span></span>
<span class="r-in"><span>                             <span class="va">sim</span><span class="op">$</span><span class="va">AInv</span>, <span class="fu"><a href="random_pibble_init.html">random_pibble_init</a></span><span class="op">(</span><span class="va">sim</span><span class="op">$</span><span class="va">Y</span><span class="op">)</span><span class="op">)</span>  </span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://www.justin-silverman.com/" class="external-link">Justin Silverman</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer></div>





  </body></html>

